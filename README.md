# programaria-sprint-dados

![Badge em Desenvolvimento](http://img.shields.io/static/v1?label=STATUS&message=FINALIZADO&color=GREEN&style=for-the-badge)

![Badge code size](https://img.shields.io/github/languages/code-size/fab-souza/programaria-sprint-dados)

| :placard: Vitrine.Dev |    |
| -------------  | --- |
| :sparkles: Nome        | **PrograMaria Sprint Dados: Ampliando fronteiras**
| :label: Tecnologias | python
| :rocket: URL         | Notebook da [Parte 1](https://www.kaggle.com/fabianadesouza/programaria-sprint-dados-parte-1), [Parte 2](https://www.kaggle.com/code/fabianadesouza/programaria-sprint-dados-parte-2) e [Parte 3](https://www.kaggle.com/code/fabianadesouza/programaria-sprint-dados-parte-3)
| :fire: Desafio     | 

![](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/7ac8de8b-4d68-4966-ad83-96df8d9dc72c#vitrinedev)

A [PrograMaria](https://www.programaria.org/) √© uma startup de impacto social que tem como miss√£o empoderar mulheres e promover diversidade e inclus√£o no mundo da programa√ß√£o e da tecnologia, por meio de oficinas, eventos e cursos de forma√ß√£o t√©cnica. 

Desde 2020, ano que comecei a pesquisar mais sobre dados, a PrograMaria foi uma das comunidades femininas que encontrei e me encantei. Tive a oportunidade de participar de alguns eventos online e foi onde encontrei uma linda rede de apoio, pois foi onde conheci muita gente maravilhosa, tanto palestrantes quanto outras participantes que estavam em uma situa√ß√£o parecida com a minha, que j√° estavam decididas a migrar de carreira ou que estavam no in√≠cio da carreira em tecnologia e queriam apoiar outras mulheres a seguirem o mesmo caminho. 

<div id='sobre'></div>

# Sobre a Sprint üìö

A Sprint foi composta por 6 dias repletos de v√≠deos e artigos voltados √† dados, em que cada dia era abordado um t√≥pico diferente. Partindo de conte√∫dos sobre carreira e processos seletivos, no primeiro dia, e concluindo com uma live, com 3 especialistas da √°rea. 

No 3¬∫ dia, o tema era Intelig√™ncia Artificial e, al√©m dos artigos e palestras, tivemos um workshop sobre Deep Learning, com a head de dados na NeuralMed, [J√©ssica dos Santos](https://www.linkedin.com/in/jessica-santos-oliveira).

## √çndice:

- [Parte 1](https://github.com/fab-souza/programaria-sprint-dados#parte-1)
- [Parte 2](https://github.com/fab-souza/programaria-sprint-dados#parte-2)
- [Parte 3](https://github.com/fab-souza/programaria-sprint-dados#parte-3)
  
# Workshop üë©üèª‚Äçüíª

## Parte 1

Come√ßamos o workshop com uma base de dados, disponibilizada no [Kaggle](https://www.kaggle.com), sobre [exames de c√¢ncer de mama](https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset) com a finalidade de  classificar os tumores em malignos (cancer√≠genos) ou benignos (n√£o cancerosos), utilizando Redes Neurais.

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/e11b63cf-2c7d-4d02-8fdf-bb5774575297)

N√£o foi preciso fazer nenhum tratamento nos dados, pois a maioria deles j√° estava no formato num√©rico e n√£o havia registros nulos ou equivocados. A √∫nica altera√ß√£o que fizemos foi criar uma nova coluna para receber o diagn√≥stico dos exames na forma de n√∫meros, j√° que eles estavam classificados, na coluna ‚Äú**diagnosis**‚Äù,  como ‚ÄúM‚Äù, para tumores malignos, e ‚ÄúB‚Äù, para benignos. 

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/bc319f78-c3ed-4c00-bb80-f11c02155ac2)

A nova coluna foi denominada como ‚Äú**diagnosis_maligno**‚Äù, em que todos os registros que estavam classificados como ‚ÄúB‚Äù, na coluna ‚Äú**diagnosis**‚Äù, foram preenchidos com ‚Äú0‚Äù, enquanto os exames que resultaram em tumores malignos, foram preenchidos com ‚Äú1‚Äù.

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/27a7e803-3892-4926-b08b-7a86989f8db3)

O pr√≥ximo passo foi separar a base de dados entre **Treino**, **Teste** e **Valida√ß√£o**. At√© o momento, eu n√£o me recordo de ter feito nenhum projeto que teve a cria√ß√£o destes tr√™s conjuntos e achei super-interessante a finalidade do terceiro. Pelo o que entendi, a ‚ÄúValida√ß√£o‚Äù √© um grupo de registros que vai dizer se os resultados obtidos nos testes est√£o indo na dire√ß√£o correta, ou seja, √© como se a Rede Neural estivesse fazendo um segundo teste e quando o resultado estiver incorreto, haver√° uma mudan√ßa nos pesos para que haja um acerto na pr√≥xima vez.

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/46c81360-57fd-488e-84f9-1bbe1519dbd0)

Antes de dar in√≠cio a cria√ß√£o do modelo, tamb√©m fizemos a normaliza√ß√£o dos dados, como uma forma de garantir que eles estejam em uma escala comum e tenham caracter√≠sticas estat√≠sticas semelhantes, por exemplo a m√©dia e a vari√¢ncia. A J√©ssica citou duas formas de se fazer a normaliza√ß√£o: 

- min-max, em que todos os registros passam a ter um intervalo de 0 √† 1;
- e padroniza√ß√£o, que dimensiona os dados para ter uma m√©dia igual a 0.

Usando a segunda op√ß√£o, obtivemos:

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/93efcbf9-0db4-444e-a45c-46d87b3fe259)

Para criar o modelo, primeiro, tivemos que importar o **Tensorflow** e **Keras**, que s√£o bibliotecas usadas na cria√ß√£o de Machine Learning e Redes Neurais, respectivamente, e que eu nunca trabalhei anteriormente.

Em seguida, fizemos a fun√ß√£o para criar o modelo.

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/7e143df5-fcb0-4ab3-9063-76039ce4c01f)

Na primeira linha, definimos que as camadas ser√£o criadas em sequ√™ncia de forma manual.

Na linha seguinte, definimos a primeira camada da Rede Neural, estabelecendo par√¢metros para os dados de entrada:

‚Äò*Dense*‚Äô significa que os neur√¥nios da Rede estar√£o interligados, ‚Äò*input_dim*‚Äô diz quantas vari√°veis de entrada a Rede vai receber, ‚Äò*units*‚Äô refere-se a quantidade de neur√¥nios que estar√£o conectados aos dados de entrada e no ‚Äò*activation*‚Äô informamos a fun√ß√£o de ativa√ß√£o dos neur√¥nios. No caso, ‚Äò*relu*‚Äô significa que os neur√¥nios s√≥ ser√£o ativados se os valores forem positivos, caso contr√°rio, a informa√ß√£o n√£o ser√° passada adiante.

Depois criamos uma camada oculta, no primeiro par√¢metro de ‚Äò*Dense*‚Äô, estamos definindo o n√∫mero de neur√¥nios desta camada, seguida por sua ativa√ß√£o.

Finalizamos com o ‚Äú1‚Äù que significa a quantidade de neur√¥nios na sa√≠da, que neste caso √© s√≥ para dizer se o tumor √© maligno ou benigno. Sua ativa√ß√£o ser√° diferente, ‚Äú*sigmoid*‚Äù, e ir√° retornar a probabilidade do resultado ser do tipo maligno.

Com o modelo criado, fizemos um *summary* para visualizar sua arquitetura. Ele tem 431 par√¢metros no total, mas de onde saiu este valor?

Na primeira linha, temos 310 par√¢metros que referem-se √†s vari√°veis de entrada, a quantidade de neur√¥nios e mais 1 vi√©s (bias) para cada um. Em seguida, temos 110 par√¢metros das camadas ocultas e seus vieses. Finalizando com 11 par√¢metros, na camada ‚Äòdense_2‚Äô, que s√£o os neur√¥nios da camada anterior com a vari√°vel de sa√≠da.

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/fc8a12db-a3ac-4119-bbde-e6d86769303a)

Para fazer a compila√ß√£o, referente a forma que a rede aprende, definimos tr√™s par√¢metros:
- *optimizer* = respons√°vel por ajustar os atributos da rede neural, como os pesos e taxas de aprendizado. Neste caso, a J√©ssica escolheu o ‚ÄòAdam‚Äô, pois ele adapta a taxa de aprendizado de cada par√¢metro com base em seus gradientes hist√≥ricos e momento, acelerando o treinamento e melhorando o desempenho da rede.
- *loss* = determina o qu√£o errado est√£o as previs√µes do modelo e podemos derivar os gradientes que s√£o usados para atualizar os pesos.
- *learning rate* = √© um hiperpar√¢metro que controla o quanto o modelo deve mudar em resposta ao erro estimado cada vez que os pesos do modelo s√£o atualizados.

```
adam = Adam(lr = 0.01)                      
model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])
```

Seguindo para o treinamento, fizemos:

```
model.fit(x = X_train, y = y_train, validation_data = (X_val, y_val), batch_size = 16, epochs = 10)
```

Definimos no ‚Äò*fit*‚Äô: o conjunto de treino, tanto X quanto y, os conjuntos de valida√ß√£o, o ‚Äò*batch_size*‚Äô, que √© o par√¢metro que determina o n√∫mero de exemplos de treinamento que ser√£o propagados pela rede de cada vez. Neste caso, o ‚Äò*fit*‚Äô pega os 16 primeiros registros, faz o treinamento deles e treina a rede. Depois ele pega os pr√≥ximos 16 registros, faz o treinamento, treina a rede e continua at√© passar por todos os registros. Finalizando com o ‚Äò*epoch*‚Äô (n√∫mero de √©pocas), que √© a quantidade de vezes que a rede vai percorrer os dados e aprender. 
No workshop, a J√©ssica fez o ‚Äò*fit*‚Äô com 10 √©pocas. Os resultados obtidos pelo modelo da J√©ssica foram:
- acur√°cia = 0.9808
- loss = 0.0971
  
Excelente.

O meu modelo ficou com:
- acur√°cia = 0.9783
- loss = 0.0981
  
Valores pr√≥ximos. üòÄ üëç

Finalizando com a avalia√ß√£o do modelo, usamos o ‚Äò*.predict()*‚Äô para fazer previs√µes com os dados do conjunto ‚ÄòX_test‚Äô e a forma escolhida para verificar os resultados foi a matriz de confus√£o. E como ela funciona?

Ela mostra o n√∫mero de previs√µes corretas e incorretas feitas pelo modelo, divididas por classe. Isso permite identificar quantas previs√µes o modelo acertou e quantas errou. Neste caso, estamos fazendo uma classifica√ß√£o bin√°ria (com duas classes), a matriz de confus√£o ter√° duas linhas e duas colunas. Cada c√©lula da matriz representa uma combina√ß√£o de classe verdadeira (real) e classe prevista (prevista pelo modelo). 

Mas antes de fazer a matriz, √© preciso lembrar que o conjunto ‚Äò*y_pred*‚Äô est√° na forma de probabilidade, ou seja, ao inv√©s de termos resultados entre 0 e 1, na verdade, temos valores de probabilidade do exame resultar em um tumor maligno ou n√£o.

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/cbe04e46-79ea-474c-a5c3-fbe73c0ddc2f)

Para apresentar a matriz, foi determinado que as probabilidades maiores do que 0,5 fossem consideradas como 1:

```
cm = confusion_matrix(y_test, y_pred > 0.5)
```

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/f1f62b3c-6400-4208-858b-5001b42b95d3)

Mas, o que os valores significam?
A c√©lula na primeira linha e primeira coluna representa verdadeiros positivos (VP), ou seja, exemplos da primeira classe que foram corretamente classificados como pertencentes √† ela. 

A c√©lula na primeira linha e segunda coluna representa falsos negativos (FN), ou seja, exemplos da segunda classe que foram incorretamente classificados como pertencentes √† primeira. 

A c√©lula na segunda linha e primeira coluna representa falsos positivos (FP), os exemplos da primeira classe que foram incorretamente classificados como pertencentes √† segunda. 

E por fim, a c√©lula na segunda linha e segunda coluna representa verdadeiros negativos (VN), exemplos da segunda classe que foram corretamente classificados como pertencentes √† ela.

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/83e188e0-d92c-4dec-bf71-a67e584a770c)

O modelo do workshop resultou em:
- 37 resultados no Verdadeiro Positivo (tumores benignos que foram classificados corretamente)
- 1 resultado no Falso Negativo (tumor benigno classificado como maligno)
- 1 resultado no Falso Positivo (tumor maligno classificado como benigno)
- 18 resultados no Verdadeiro Negativo (tumores malignos classificados corretamente)

![parte1](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/8b58400b-7c5f-4c6a-9499-2f95b40448a2)

Enquanto no meu modelo, tive:

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/a1f26952-32c5-4f3b-8bf2-3b72d52fad89)

- 34 resultados no Verdadeiro Positivo
- nenhum no Falso Negativo
- 2 resultados no Falso Positivo
- e 21 resultados no Verdadeiro Negativo

Acredito que n√£o cheguei ao mesmo resultado, (1¬∫) porque n√£o trabalhamos com os mesmos registros, ou seja, n√£o utilizamos um ‚Äòseed‚Äô na hora de fazer a divis√£o entre *Treino*, *Teste* e *Valida√ß√£o*, que fez com que tiv√©ssemos exames diferentes nos conjuntos. (2¬∫) porque o modelo do workshop teve um desempenho melhor do que o meu, tanto na acur√°cia quanto no ‚Äò*loss*‚Äô. 

<a href='#sobre'>üîº Voltar ao √çndice</a>

## Parte 2

Na segunda parte do workshop, fizemos um modelo para distinguir e classificar imagens de exames m√©dicos, desta vez utilizando Redes Convolucionais. A base de dados tamb√©m √© do Kaggle, o [Medical MNIST](https://www.kaggle.com/datasets/andrewmvd/medical-mnist). 

Ap√≥s fazer o carregamento dos arquivos, o caminho de cada imagem tornou-se uma vari√°vel e para saber seu tipo, criamos uma nova coluna para armazenar esta informa√ß√£o.

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/01774eb7-fb06-4914-be5a-2a3670807b79)

A separa√ß√£o de **Treino** e **Teste** foi parecida com a primeira parte do workshop, ou seja, importa√ß√£o de biblioteca, cria√ß√£o de *X_train*, *X_test*, *y_train* e *y_test* e determinando o tamanho do teste. No caso da leitura de imagens, n√£o foi preciso criar um conjunto de *Valida√ß√£o*, porque usamos uma classe que j√° faz isso, o **ImageDataGenerator**.

Para defini-la, primeiro, criamos uma vari√°vel que recebeu alguns par√¢metros de processamento de imagens: *rescale* e *validation_split*. Uma para multiplicar os dados por um valor fornecido antes de qualquer outra transforma√ß√£o, como uma forma de normaliza√ß√£o, e para reservar uma fra√ß√£o dos dados de treinamento para valida√ß√£o, respectivamente.

Em seguida, criamos o gerador de treino (*train_generator*) depois o gerador de valida√ß√£o (*valid_generator*). Definimos em ambos, o *dataframe*, a coluna ‚Äòx‚Äô, a coluna ‚Äòy‚Äô, o tamanho das imagens, as cores das imagens (no caso, preto e branco = escalas em cinza), a quantidade de arquivos que ser√£o carregados ao mesmo tempo e o que aquele gerador √© (treino ou valida√ß√£o).

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/69abe1a5-7f62-4b3d-99c7-76b3f42821bd)

Seguimos para a cria√ß√£o da fun√ß√£o que ir√° construir o modelo:

```
def build_model():

    model = Sequential()

    model.add(layers.Conv2D(filters = 32, kernel_size = 2, activation = "relu", input_shape = (64, 64, 1)))
    model.add(layers.MaxPooling2D(pool_size = 2))
    model.add(layers.Dropout(0.3))

    model.add(layers.Flatten())

    model.add(layers.Dense(28, activation = 'relu'))
    model.add(layers.Dense(6, activation = 'softmax'))

    return model
```

Na primeira linha, definimos que as camadas ser√£o criadas em sequ√™ncia, igual foi feito no primeiro modelo.

Depois, criamos a primeira camada, uma camada convolucional com sua quantidade de filtros, tamanho das matrizes, tipo de ativa√ß√£o e o formato das imagens, em escala de cinza.

Na pr√≥xima camada, *MaxPooling2D*, ela reduz a amostra de entrada ao longo de suas dimens√µes espaciais (altura e largura), pegando o valor m√°ximo sobre uma janela de entrada (de tamanho definido por *pool_size*) para cada canal da entrada e calcula sua m√©dia.

Na camada de *Dropout*, tentamos reduzir a ocorr√™ncia de *overfit* no modelo. Neste caso, estamos desabilitando 30% dos neur√¥nios da rede.

Com o *Flatten*, fazemos com que a matriz de entrada seja ‚Äòachatada‚Äô, na forma de um array, antes de pass√°-la para a camada densa. 

Depois criamos uma camada oculta densa, definindo seu n√∫mero de neur√¥nios, seguida por sua ativa√ß√£o (*relu*).

Finalizando com a camada de sa√≠da com 6 neur√¥nios, referentes √†s categorias de imagens, e sua ativa√ß√£o, que neste caso √© ‚Äú*softmax*‚Äù, que retorna a probabilidade da imagem pertencer √†s categorias e a soma delas resulta em 1. Por exemplo:
- AbdomenCT = 0,2   
- Hand = 0,1        
- CXR = 0,25         
- HeadCT = 0,2      
- ChestCT = 0,25     
- BreastMRI = 0,27

Para criar o modelo, fizemos um *summary* para visualizar sua arquitetura e vemos que o modelo tem mais do que 850 mil par√¢metros.

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/bf06d4b3-9004-45c0-96fd-8584e15f4466)

Passando para a compila√ß√£o do modelo, tamb√©m definimos tr√™s par√¢metros (*optimizer*, *loss* e *learning rate*) como foi feito no primeiro modelo. A √∫nica diferen√ßa √© que no *loss*, mudamos de *binary_crossentropy* para *categorical_crossentropy*, pois as sa√≠das s√£o exames de diferentes tipos.

Antes de iniciar o treinamento, definimos mais algumas fun√ß√µes de otimiza√ß√£o, tamb√©m chamados de *callbacks*: *ModelCheckpoint* e *EarlyStopping*. O primeiro, salva o melhor modelo enquanto os treinamentos ocorrem. Nele, definimos como os modelos ser√£o chamados, a m√©trica usada para avaliar o desempenho do modelo (*val_loss*), o modo de avalia√ß√£o (*min* = queremos obter o menor valor treinado), no *verbose* determinamos se isso ser√° feito em todas as √©pocas e confirmamos o salvamento do melhor modelo.

No segundo, interrompemos o treinamento mais cedo, quando a m√©trica monitorada para de melhorar. Definimos a m√©trica que dever√° ser observada (*val_loss*), o treinamento ser√° interrompido quando n√£o houver uma melhoria absoluta maior que 0,001 (*min_delta*) por 5 √©pocas consecutivas (*patience*) e o modo √© definido como *min*, o que significa que o treinamento ser√° interrompido quando a quantidade monitorada parar de diminuir.

```
model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
checkpoint = ModelCheckpoint('medical_image_model.hdf5', monitor = 'val_loss', verbose = 1, mode = 'min', save_best_only = True)
early_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, patience = 5, mode = 'min', verbose = 1)
```

Para o treinamento do modelo, tamb√©m usamos o *.fit()*, igual foi feito na primeira parte do workshop. Tamb√©m informamos que o modelo deve usar *train_generator* como dados de treinamento, o uso dos callbacks que criamos anteriormente, o n√∫mero de etapas por √©poca (*train_generator.samples//BATCH_SIZE*), o uso de *valid_generator* como dados de valida√ß√£o, o n√∫mero de etapas de valida√ß√£o (*valid_generator.samples//BATCH_SIZE*) e o modelo ser√° treinado por, no m√°ximo, 25 √©pocas.

```
model.fit(train_generator, callbacks = [checkpoint, early_stop], steps_per_epoch = train_generator.samples//BATCH_SIZE, 
          validation_data = valid_generator, validation_steps = valid_generator.samples//BATCH_SIZE, epochs = 25)
```

No meu caso, parou de ser treinado na √©poca 12 com uma acur√°cia na valida√ß√£o de 0,9991 e uma perda na valida√ß√£o de 0,0028. Ambos foram um pouco melhor do que o modelo apresentado pela J√©ssica, que obteve *val_loss* = 0,0041 e *val_accuracy* = 0,9986.

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/92d08ca3-b4c1-4731-a41f-d7306fc4de05)

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/68764596-0ee9-4892-b35e-cc598cdb5ca9)

Para aplicar o modelo treinado no conjunto de teste, n√£o foi criado mais um *ImageGenerator* para eles, usamos duas fun√ß√µes do **Keras** que fazem o carregamento e a leitura das imagens, o *load_img* e *img_to_array*, pois a quantidade de arquivos era bem menor do que o conjunto de treino. Usamos o *.predict* no conjunto de teste e as previs√µes foram armazenadas na vari√°vel *y_pred*. Mas diferente do primeiro caso, que a sa√≠da era bin√°ria, n√£o √© poss√≠vel avaliar o resultado fazendo *y_pred > 0.5*. Foi preciso usar um *.argmax(axis = 1)* para retornar o √≠ndice com o maior valor ao longo do eixo especificado, ou seja, o √≠ndice com o valor m√°ximo ao longo do eixo 1 foi salvo na nova vari√°vel. Assim, obtivemos a classe prevista para cada imagem de teste.

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/8273aecf-7a9d-4eb6-be73-8dbc303f6073)

As classes dos exames ainda estavam como *string* ('AbdomenCT', 'BreastMRI', 'CXR', 'ChestCT', 'Hand', 'HeadCT') e utilizamos um *LabelEncoder* para transform√°-las em uma sequ√™ncia de n√∫meros, igual as previs√µes. 

E finalizamos a avalia√ß√£o com uma matriz de confus√£o, nela observamos que n√£o obtive bons resultados. Com exce√ß√£o dos exames do tipo 2 e 4, pois eles tiveram os maiores valores na linha diagonal da matriz, os demais exames foram mais classificados em outras categorias.

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/0d14b5ee-693f-40d7-8a3a-b0574985f985)

Durante o workshop, a J√©ssica reparou que o *LabelEncoder* mudaria as classes dos exames seguindo uma ordem alfab√©tica, enquanto o *y_pred* seguiu a ordem que as classes foram aparecendo. Eu tentei corrigir este erro ao fazer um *LabelEncoder.fit*, mas acho que n√£o obtive sucesso. Fica de li√ß√£o para o pr√≥ximo projeto.

<a href='#sobre'>üîº Voltar ao √çndice</a>

## Parte 3:

Para finalizar o workshop, a J√©ssica ensinou como fazer uma rede sem precisar definir sua arquitetura, usar uma que j√° aprendeu a identificar outras categorias de imagens e adapt√°-la ao nosso projeto, ou seja fazer um **transfer learning**. A maior diferen√ßa entre este modelo e o anterior, √© que desta vez usamos imagens coloridas, pois a arquitetura pronta foi treinada desta forma. Ent√£o, ap√≥s fazer a importa√ß√£o das bibliotecas e arquivos, separar *Treino* e *Teste*, criamos o *train_generator* e *valid_generator* para imagens coloridas.

```
train_generator = data_generator.flow_from_dataframe(dataframe = df_train, x_col = 'path', y_col = 'class', 
                                                     class_mode = 'categorical', batch_size = BATCH_SIZE, 
                                                     target_size = (64,64), subset = 'training', color_mode = 'rgb')
valid_generator = data_generator.flow_from_dataframe(dataframe = df_train, x_col = 'path', y_col = 'class', 
                                                     class_mode = 'categorical', batch_size = BATCH_SIZE, 
                                                     target_size = (64,64), subset = 'validation', color_mode = 'rgb')
```

Na cria√ß√£o do *Transfer Learning*, usamos a rede *MobileNetV2*, por ela ser menor e conseguir treinar o modelo mais r√°pido. Tamb√©m definimos usar todos os pesos das milh√µes de imagens que passaram por ela, no *include_top* definimos que n√£o queremos as 1000 classes de sa√≠da, e sim, as 6 categorias de exames, e no *input_shape*, o tamanho das imagens. Neste modelo, n√£o usamos o *MaxPooling2D* e *Dropout*, mas fizemos o congelamento de algumas camadas no *for*. Transformamos a sa√≠da da camada anterior em uma camada densa ao fazer *x = base_model.output*, seguido por *x = layers.GlobalAveragePooling2D()(x)* que, diferente do *Flatten*, traz a m√©dia geral de matriz. Concluindo com o uso da camada densa na constru√ß√£o do modelo, *model = Model(base_model.input, predictions)*.

```
def build_model2(shape):

    base_model = MobileNetV2(weights = "imagenet", include_top = False, input_shape = shape)
    # congelando camadas que n√£o iremos treinar.
    # para congelar alguns layers espec√≠ficos basta passar o indice: for layer in mobile.layers[:5]:
    for layer in base_model.layers[:3]:
        layer.Trainable = False

    x = base_model.output
    x = layers.GlobalAveragePooling2D()(x)
    predictions = layers.Dense(6, activation = 'softmax')(x)

    model = Model(base_model.input, predictions)

    return model
```

Constru√≠mos o modelo e ao fazer o resumo, vemos que ele possui mais do que 2 milh√µes de par√¢metros. 

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/821dcfc9-3be7-4e3d-8d18-080184894318)

Fizemos a cria√ß√£o dos callbacks *ModelCheckpoint* e *EarlyStopping*, seguido pela compila√ß√£o do modelo, que chegou a um bom resultado um pouco mais r√°pido, em 10 √©pocas. Aplicamos o modelo no conjunto de teste e obtive um resultado pior, porque os exames foram classificados apenas como tipo 4 e 5.

![image](https://github.com/fab-souza/programaria-sprint-dados/assets/67301805/f260f192-03fd-457b-ab51-0cc4df5d286a)

<a href='#sobre'>üîº Voltar ao √çndice</a>

# Conclus√£o üèÅ

Antes deste workshop, eu nunca tinha trabalhado com Deep Learning, muito menos com Rede Neural e achei interessante o fato de poder atribuir ‚Äúpesos‚Äù √†s vari√°veis, sem precisar balancear os dados, algo que fiz nos meus projetos anteriores. Mesmo n√£o obtendo bons resultados na classifica√ß√£o de imagens, eu gostei de ter aprendido uma nova ferramenta, de ter este primeiro contato com este tipo de modelo de Machine Learning e at√© consigo imaginar alguns projetos pessoais em que posso replicar este conhecimento.

Sei que preciso corrigir a quest√£o do *labelEncoder*, mas adquiri um novo interesse e pretendo melhorar a forma que utilizo esta ferramenta. 

---

Muito obrigada por chegar at√© aqui e at√© a pr√≥xima ü§ó

## Ferramentas utilizadas üß∞
<p>
  <a href="https://www.python.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> </a>
  <a href="https://pandas.pydata.org/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/2ae2a900d2f041da66e950e4d48052658d850630/icons/pandas/pandas-original.svg" alt="pandas" width="40" height="40"/> </a> 
  <a href="https://numpy.org/" target="_blank" rel="noreferrer"> <img src="https://numpy.org/images/logo.svg" alt="numpy" width="40" height="40"/> </a>
  <a href="https://matplotlib.org/" target="_blank" rel="noreferrer"> <img src="https://matplotlib.org/_static/images/documentation.svg" alt="matplotlib" width="40" height="40"/> </a>
  <a href="https://www.tensorflow.org/?hl=pt-br" target="_blank" rel="noreferrer"> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Tensorflow_logo.svg/115px-Tensorflow_logo.svg.png?20170429160244" alt="tensorflow" width="40" height="40"/> </a>
  <a href="https://keras.io/" target="_blank" rel="noreferrer"> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Keras_logo.svg/1200px-Keras_logo.svg.png" alt="keras" width="40" height="40"/> </a>
     </p>
